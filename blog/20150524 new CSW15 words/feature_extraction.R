#########################################
##### summarise output from GoogleTrends generated by collate_gtrend
##### creating features for further analyses
##### shortcut: load RData saved in main folder as List_word_trends.RData
#########################################

setwd("~/GitHub/Scrabble/blog/20150524 new CSW15 words")

require(lubridate)
require(zoo)
require(dplyr)
require(tidyr)

# if variable trends not in environ, uncomment below to execute
#load("List_word_trends.RData")
full.trends <- trends  #backup

########### Initial setup
# find those with no freq data
freq.col <- sapply(trends, function(x) length(x$freq))  # expected value 2, 0 means no data
nofreq <- names(freq.col[freq.col==0])
# eliminate those from trends
trends[which(freq.col==0)] <- NULL
words <- names(trends)

# initiate trend features dataframe
tf <- data.frame(word=names(trends), stringsAsFactors=FALSE)


########### Handle some dirty data
#search for "polluted" frequency (i.e.non date in frequency table, e.g. text strings)
check.nondate <- function(datestr) {
  nondate <- grepl("^20", datestr)  # check if starts with "20" (i.e. year 2000 and above)
  return(which(!nondate))
}
nondate.loc <- sapply(trends, function(x) check.nondate(x$freq$StartDate))
polluted <- which(sapply(nondate.loc, length) > 0)
# remove all the polluted rows
for (rem in names(polluted)) {
  trends[[rem]]$freq <- trends[[rem]]$freq[-nondate.loc[[rem]], ]
  # reconvert to numeric, as the initial pollution caused the values to be coded as factor
  trends[[rem]]$freq$RelFreq <- as.integer(as.character(trends[[rem]]$freq$RelFreq))
}

########### Handle week/month data frequency, simplifying all to monthly
# record feature whether data set is weekly or monthly
datepoints <- sapply(trends, function(x) nrow(x$freq))
tf$data.freq <- "Weekly"  # default
tf$data.freq[which(datepoints==137)] <- "Monthly"  #those with 137 rows of Google trendsdata
tf$data.freq <- factor(tf$data.freq)
# convert all data points to start date - SUPERCEDED by converting to year-month below
get.startdate <- function(datestr) {
  return(ymd(substr(as.character(datestr), 1, 10), truncated=1))  # truncated to allow month without dates
}
#trends <- lapply(trends, function(x) {
#  x$freq$StartDate <- get.startdate(x$freq$StartDate)
#  x
#  })
# convert all data points to year-month pair
get.yearmon <- function(datestr) {
  return(as.yearmon(substr(as.character(datestr), 1, 7)))
  #  return(substr(as.character(datestr), 1, 7))
}
trends <- lapply(trends, function(x) {
  x$freq$YM <- get.yearmon(x$freq$StartDate)
  x
})
#summarise to keep only highest value in a month
trends <- lapply(trends, function(x) {
  # note: need to coerce YM to numeric before converting back, as dplyr can't handle yearmon
  y <- x$freq %>% group_by(YM=as.numeric(YM)) %>% summarize(maxf=max(RelFreq))
  y$YM <- as.yearmon(y$YM)
  x$freq <- y
  x
})

############ feature extraction
# function to build additional features from frequency
freq.ext <- function(freq) {
  cuts <- c(freq$YM[1], as.yearmon(c("2008-01", "2012-01")), freq$YM[nrow(freq)])
  #divide into 3 time periods
  freq$YM <- as.numeric(freq$YM)
  freq$cuts <- cut(freq$YM, as.numeric(cuts), include.lowest=TRUE)
  sect <- freq %>% group_by(cuts) %>%
    summarise(zero.pct=sum(maxf==0)/n(),
              ave = mean(maxf),
              peak = max(maxf),
              top = if (peak==100) TRUE else FALSE)
  sct <- sect[, -1]
  nsct <- names(sct)
  #unfold all features into a dataframe
  return(as.data.frame(
    do.call(c, lapply(sct, function(x) as.list(as.matrix(x))))))
}
# create data frame of  frequency features
freq.features <- do.call(rbind, lapply(trends, function(x) freq.ext(x$freq)))

# function to build additional features from region
reg.ext <- function(reg) {
  cat("OK")
  if (length(reg)==0) return(0) # no features
  topreg <- as.character(reg$Region[1])
  us.idx <- which(reg$Region == "United States")
  us.idx <- if (length(us.idx)==0) 0 else us.idx
  us.val <- if (us.idx==0) 0 else reg$RelFreq[us.idx]
  uk.idx <- which(reg$Region == "United Kingdom")
  uk.idx <- if (length(uk.idx)==0) 0 else uk.idx
  uk.val <- if (uk.idx==0) 0 else reg$RelFreq[uk.idx]
  return(data.frame(topreg=topreg, us.idx=us.idx, us.val=us.val,
                    uk.idx=uk.idx, uk.val=uk.val, stringsAsFactors=FALSE))
}
# create data frame of  region features
reg.features <- do.call(rbind, lapply(trends, function(x) reg.ext(x$region)))

#### unused
#find those with no search data
#search.col <- sapply(trends, function(x) length(x$search))  # expected value 2, 0 means no data
#nosearch <- names(search.col[search.col==0])
#trends.nosearch <- trends
#trends.nosearch[which(search.col==2)] <- NULL

#find those with both no region and no search data
freqonly <- names(trends[region.col==0 & search.col==0])
##############

#save features set
tf <- cbind(tf, freq.features, reg.features)
save(tf, file="features.RData")
